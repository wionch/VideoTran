# 项目思路：AI 视频翻译与配音

## 核心目标

将一个包含音视频的 A 视频文件，通过 AI 工具链，自动翻译成指定语言，并生成一个配音和字幕都替换为目标语言的 B 文件。

## 使用场景

处理包含复杂音景（背景音乐、环境音、多人对话、方言等）的视频文件，实现高质量的自动化翻译和配音。

**核心需求:**

1. **音轨分离:** 自动分离人声和背景音。
2. **语音识别:** 将纯净人声转换为带时间戳和说话人角色的文本。
3. **文本翻译:** 智能、流畅地将源语言文本翻译为目标语言。
4. **语音合成:** 使用克隆的音色或高质量预设音色，根据翻译文本生成新语音。
5. **音频合并:** 将新生成的语音与原始背景音按时间戳精确合并。
6. **视频合成:** 将原视频的画面与新生成的音轨、新字幕合并，产出最终成品。

## 工具/模块介绍

* **大语言模型 (LLM):** 如 `GEMINI/DeepSeek`，负责文本的智能翻译，确保译文自然、准确，并符合上下文语境。
* **IndexTTS:** 负责新音频的生成。可通过声音克隆技术，使翻译后语音的音色、语调与原说话人保持一致。
* **python-audio-separator:** 负责音频中人声和非人声（背景音乐、环境音）的精确分离。它通过加载 `UVR (Ultimate Vocal Remover)` 的 `MDX-Net` 模型，能够高效地处理复杂音频。
* **whisperX:** 负责从人声中提取文本，并进行说话人角色识别（Diarization），输出带精确时间戳和角色标签的文本。
* **FFmpeg:** 开源音视频处理工具集，用于执行底层的视频操作，如移除字幕轨道、合并音视频和烧录新字幕。

## 工作流程

### 第一阶段：音频处理

**目标：** 将原始视频中的音频，处理成一段翻译好的、带背景音的完整配音文件。

1. **提取与分离音轨:**
    * 首先使用 `FFmpeg` 从原视频中提取完整的音轨。
    * 然后调用 `python-audio-separator`，加载 `UVR-MDX-NET-Inst_HQ_5.onnx` 模型，将该音轨处理成**纯净人声音轨**和**背景音轨**两个文件。

2. **识别角色与生成文本:**
    * 使用 `whisperX` 处理上一步得到的人声音轨。
    * 在此步骤中，启用其**说话人角色识别**功能 (`--diarize`)。
    * 产出一个结构化的 `JSON` 文件，其中包含每个语音片段的文本内容、开始/结束时间，以及唯一的说话人ID（如 `SPEAKER_00`, `SPEAKER_01`）。

3. **批量翻译:**
    * 编写一个脚本，读取上一步生成的 `JSON` 文件。
    * 调用大语言模型（LLM）的 API，将文件中所有的文本片段批量翻译成目标语言。
    * 将翻译结果更新回 `JSON` 文件，为每个片段增加一个 `translated_text` 字段。

4. **生成新语音:**
    * 基于更新后的 `JSON` 文件，为每一段翻译后的文本。
    * 调用 `IndexTTS`，（可选）参照原始说话人的音色，生成对应的语音片段。每个片段都是一个独立的 `.wav` 文件。

5. **合并最终音轨:**
    * 创建一个新的空白音轨。
    * 根据 `JSON` 文件中记录的精确时间戳，将所有新生成的零散语音片段，逐一“粘贴”到空白音轨的正确位置上。
    * 最后，将原始的**背景音轨**与这个新合成的配音轨道混合，生成最终的完整配音文件 `final_dubbed_audio.wav`。

### 第二阶段：视频处理与合成

**目标：** 将原视频、新音轨和新字幕无缝合成为最终视频。

1. **移除原始软字幕 (可选):**
    * 使用 `FFmpeg` 检查并移除原视频中包含的**软字幕**轨道。软字幕独立于视频画面，可以被干净地移除。
    * **注意：** 此流程不处理**硬字幕**（已烧录在画面上的字幕）。

2. **生成 SRT 字幕文件:**
    * 根据第一阶段生成的、包含翻译文本和时间戳的 `JSON` 文件。
    * 自动生成一个标准格式的 `.srt` 字幕文件。

3. **最终合成:**
    * 调用 `FFmpeg` 或 `MoviePy` 等库。
    .   将**无字幕的视频**作为视频源。
    * 将第一阶段生成的**完整配音文件**作为新的音轨。
    * 将上一步生成的 **`.srt` 文件**作为要烧录的新字幕。
    * 执行合并与烧录操作，输出最终的成品视频。

### 高级功能：字幕校对与验证

此模块为可选步骤，用于处理原视频包含**硬字幕**的场景，旨在通过 OCR 技术提升字幕准确性。

1. **定时截图:** 根据 `whisperX` 生成的时间戳，使用 `FFmpeg` 截取每一句字幕出现时间点的视频帧。
2. **字幕区域提取:** 根据用户预先设定的字幕Y轴坐标范围，从截取的视频帧中裁剪出包含字幕的横向图片条。
3. **批量 OCR 识别:** 将多个字幕图片条合并成一张大图，提交给 OCR 服务或视觉大模型进行文字识别，返回文本内容和在图中的精确坐标。
4. **文本校对:** 将 OCR 识别出的字幕文本与 `whisperX` 生成的文本进行比对。利用大语言模型进行智能分析，修正错别字、优化表达，并生成一份经过双重验证的、更精确的字幕 `JSON` 文件。
5. **后续应用:** 这份校对过的 `JSON` 文件可用于生成更准确的 `.srt` 字幕和 TTS 语音。
