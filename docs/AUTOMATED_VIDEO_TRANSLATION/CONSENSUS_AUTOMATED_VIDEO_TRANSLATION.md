# 共识文档：自动化视频翻译 (AUTOMATED_VIDEO_TRANSLATION)

## 1. 需求总览

本项目旨在创建一个自动化的视频翻译管道，将包含中文对白的视频，处理成包含英文对白和英文硬字幕的新视频。核心要求是保留原说话人的音色、语调和情感，能有效处理视频中已存在的硬字幕，并对AI转录的字幕进行校对。

## 2. 验收标准

- **输入**: 一个 `.mp4` 或 `.mkv` 格式的视频文件。
- **输出**: 一个与输入视频同分辨率的 `.mp4` 文件。
- **音频**: 原视频的中文对白被替换为英文对白，背景音保留。
- **音色**: 翻译后的英文语音在音色、情感上与原说话人高度相似。
- **字幕**: 视频包含“烧录”好的英文硬字幕，且字幕文本经过校对修正。
- **原字幕**: 如果原视频有硬字幕，输出视频的相应位置应被有效遮蔽，无明显残留。
- **功能**: 所有功能通过一个统一的Python脚本（命令行工具）来调用。
- **灵活性**: 用户可配置字幕校对模式和原字幕处理策略。

## 3. 技术实现方案

经过对齐阶段的讨论和研究，我们确定采用以下技术栈和方案：

- **主控脚本**: Python 3.x
- **核心依赖**: 
    - `ffmpeg`: 用于所有音视频的提取、合并、编码等底层操作。
    - `conda`: 用于管理 `whisper` 环境。

### 3.1. 流水线模块分解

整个处理流程将分为以下几个独立的模块，依次执行：

1.  **音频提取与分离 (Audio Extraction & Separation)**
    - **工具**: `ffmpeg` + `audio_separator`
    - **步骤**: 分离出 `vocals.wav` (人声) 和 `background.wav` (背景声)。

2.  **语音识别与说话人分析 (ASR & Diarization)**
    - **工具**: `whisperX`
    - **步骤**: 处理 `vocals.wav`，生成带时间戳的中文文本 (`.srt`) 和说话人信息。

3.  **字幕校对 (Subtitle Correction) (新增)**
    - **工具**: `OpenCV-Python`, `easyocr` (或其它OCR库), `requests` (LLM API)
    - **步骤**: 对 `whisperX` 生成的 `.srt` 文件进行修正，生成 `corrected.srt`。
    - **模式 (可配置)**:
        - **OCR模式**: 从原视频画面提取硬字幕文本，与 `.srt` 文件对比修正。
        - **LLM模式**: 使用大语言模型润色 `.srt` 文件文本。
        - **混合模式 (默认)**: 结合ASR、OCR、LLM三方信息进行综合修正。

4.  **原字幕处理 (Hardsub Masking)**
    - **工具**: `OpenCV-Python`, `Numpy`
    - **步骤**: 根据 `corrected.srt` 的时间戳，处理原视频对应帧，生成无字幕视频或带遮罩的视频。
    - **策略 (可配置)**:
        - **遮罩策略 (默认)**: 在最终合成阶段，对有原字幕的区域进行模糊或遮罩，同时渲染新字幕。
        - **净版策略**: 生成一个完整的无字幕视频 (`no_sub_video.mp4`)。

5.  **文本翻译 (Text Translation)**
    - **工具**: `requests` 或相关API的SDK。
    - **步骤**: 调用 `DeepSeek` 等API，将 `corrected.srt` 中的中文文本翻译为英文。

6.  **语音克隆与合成 (Voice Cloning & TTS)**
    - **工具**: `OpenVoice`
    - **步骤**: 根据说话人信息和翻译后的文本，合成新的英文对白音轨 (`translated_vocals.wav`)。

7.  **最终合成 (Final Composition)**
    - **工具**: `ffmpeg`
    - **步骤**: 将无字幕视频(或原视频)、新的音频轨道、新的字幕文本，通过单次处理（或多次，取决于原字幕处理策略）合成为最终视频。

## 4. 约束与集成策略

- **API Keys**: 翻译和校对模块需要用户通过配置文件或环境变量提供API Key。
- **模型下载**: `audio_separator`, `whisperX`, `OpenVoice`, OCR模型都需要下载预训练模型。脚本需要有首次运行时的模型下载与缓存机制。
- **错误处理**: 流程中的每一步都需要有明确的错误处理和日志记录，方便定位问题。
- **配置化**: 关键参数（如字幕检测区域、颜色阈值、校对模式、原字幕处理策略等）应设计为可配置项。
