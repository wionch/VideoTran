# 任务共识文档 (Consensus): AUTOMATED_VIDEO_TRANSLATION

本文件记录了“自动化视频语音翻译”任务最终确定的需求、范围和技术方案，作为后续架构设计和开发工作的唯一依据。

## 1. 需求描述 (Requirements)

开发一个模块化的代码库，实现视频的自动化语音翻译。系统能够接收一个视频文件，将其中的一种语言（如中文）的语音对话，翻译成另一种语言（如英文），并生成保留原始说话人音色的新音频。最终产出一个音轨被替换、并带有可选翻译字幕的视频文件。

## 2. 验收标准 (Acceptance Criteria)

- [ ] **功能**: 系统能够完整执行从视频输入到视频输出的全流程。
- [ ] **[已知限制]** 多说话人: 当前版本不进行说话人识别，采用‘孤岛’策略处理每个语音片段，以保证角色身份的正确性。原定的多说话人音色克隆功能已变更。
- [ ] **输入**: 接受一个视频文件路径、源语言代码、目标语言代码作为输入。
- [ ] **输出**:
    -   一个与原视频分辨率、时长相同的视频文件，但音轨已被替换为翻译后的版本。
    -   一个独立的、与视频同步的翻译后字幕文件（`.srt`格式）。
- [ ] **代码质量**: 代码库应采用模块化设计，具备清晰的接口定义和良好的可读性。

## 3. 技术实现方案 (Technical Plan)

- **核心流程**: 遵循“对齐”阶段优化的工作流，包括：初始化、音频分析（提取、分离、说话人日志）、文本处理（翻译）、语音合成（音色提取、生成、时长对齐）、音频合成和视频制作。
- **关键组件**:
    - **视频/音频处理**: `ffmpeg`
    - **音轨分离**: `audio_separator`
    - **语音转录与说话人识别**: `whisperX`
    - **文本翻译**: LLM API (如 DEEPSEEK, GPT, Gemini)
    - **语音克隆**: `OpenVoice v2` (首选)
- **架构**: 采用模块化代码库结构，而非单脚本。

## 4. 技术约束与边界 (Constraints & Scope)

- **口型同步**: 任务不保证实现像素级口型同步，仅通过控制生成语音时长来初步对齐。
- **情感迁移**: 尽力模仿，但不保证100%还原。
- **OCR功能**: OCR校正功能被明确排除在当前版本范围之外。
- **交付物**: 一个模块化的Python代码库。

## 5. 集成策略 (Integration Strategy)

各个模块将通过定义好的文件接口（例如，一个模块的输出是一个文件，作为下一个模块的输入）和函数调用进行集成。一个主控制器（`main.py` 或 `pipeline.py`）将负责按顺序调用各个模块，并管理整个流程。

## 6. 任务边界 (Task Boundaries)

任务的重点是后端处理逻辑。不包含任何形式的UI（Web或桌面）。配置将通过配置文件或命令行参数进行管理。
